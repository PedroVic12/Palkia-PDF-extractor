import pandas as pd
import re
import fitz

# ===============================================================
# CLASSE: ETLRepository (MODEL - Camada de Acesso a Dados)
# ===============================================================

class ETLRepository:
    """Gerencia a lógica de Extração de dados de baixo nível para documentos PDF."""

    def __init__(self):
        """Inicializa o ETLRepository."""
        pass

    def extract_text_from_pdf(self, pdf_path, page_range=None):
        """
        Extrai texto de um arquivo PDF, opcionalmente limitando a um intervalo de páginas.

        Args:
            pdf_path (str): O caminho para o arquivo PDF.
            page_range (list, optional): Uma lista de índices de páginas (base 0) a serem processadas. Se None, todas as páginas são processadas. Defaults to None.

        Returns:
            str: O texto concatenado das páginas extraídas, com marcadores de página.
        """
        doc = fitz.open(pdf_path)
        full_text = ""
        
        # Determina as páginas a serem processadas
        if page_range is None:
            pages_to_process = range(len(doc))
        else:
            # Filtra páginas para garantir que estão dentro do limite do documento
            pages_to_process = [p for p in page_range if p < len(doc)]
        
        for page_num in pages_to_process:
            page = doc.load_page(page_num)
            full_text += f"\n--- Página {page_num + 1} ---\n" # Adiciona marcador de página
            full_text += page.get_text()
        
        doc.close()
        return full_text

    def _clean_contingency_name(self, contingency_name, add_lt_option, prev_part_ends_with_lt=False):
        """
        Limpa e padroniza o nome de uma contingência, removendo termos desnecessários e adicionando 'LT' se aplicável.

        Args:
            contingency_name (str): O nome original da contingência.
            add_lt_option (bool): Se True, tenta adicionar 'LT' se 'kV' estiver presente e 'LT' não for duplicado.
            prev_part_ends_with_lt (bool, optional): Indica se a parte anterior da contingência (em caso de múltiplas) termina com 'LT'. Usado para evitar duplicação. Defaults to False.

        Returns:
            str: O nome da contingência limpo e padronizado.
        """
        # Remove o texto "Contingência Dupla" e variações (ex: "Contingência Dupla da", "Contingência Dupla das")
        cleaned_name = re.sub(r'Contingência Dupla (da|das)?\s*', '', contingency_name).strip()
        
        # Adiciona "LT" se necessário, evitando duplicações e garantindo formato
        if add_lt_option:
            if not cleaned_name.startswith('LT ') and ' kV ' in cleaned_name:
                # Se não começa com 'LT ' e contém ' kV ', adiciona 'LT '
                cleaned_name = 'LT ' + cleaned_name
            elif cleaned_name.startswith('LT LT '):
                # Corrige caso haja "LT LT " duplicado no início
                cleaned_name = cleaned_name.replace('LT LT ', 'LT ')
            elif prev_part_ends_with_lt and cleaned_name.startswith('LT '):
                # Remove 'LT ' duplicado se a parte anterior já terminou com 'LT'
                cleaned_name = cleaned_name[3:].strip() # Remove apenas o primeiro 'LT ' 
        return cleaned_name

    def _parse_contingency_line(self, contingency_raw_line, process_options, prazo_atual, enable_regex_processing=True):
        """
        Processa uma linha de texto bruta identificada como contingência, extraindo os detalhes.
        Encapsula a lógica de identificação e separação de contingências duplas.

        Args:
            contingency_raw_line (str): A linha de texto da contingência (ex: '• Contingência Dupla LT X e LT Y').
            process_options (dict): Opções de processamento, como 'separar_duplas' e 'adicionar_lt'.
            prazo_atual (str): O prazo atual (Curto Prazo ou Médio Prazo).
            enable_regex_processing (bool, optional): Se True, ativa o processamento de regex para contingências duplas. Defaults to True.

        Returns:
            list: Uma lista de dicionários, onde cada dicionário representa uma contingência extraída.
        """
        contingencias_data = []
        contingencia = contingency_raw_line.replace('•', '').replace('-', '') # Extração bruta
        futura = "SIM" if prazo_atual == "Curto Prazo" else "NÃO"

        if enable_regex_processing:
            if 'Contingência Dupla' in contingencia and process_options['separar_duplas']:
                contingencia_limpa = re.sub(r'Contingência Dupla (da|das)?\s*', '', contingencia).strip()

                if ' e ' in contingencia_limpa:
                    partes = contingencia_limpa.split(' e ')
                    for i, parte in enumerate(partes):
                        parte = parte.strip()
                        prev_part_ends_with_lt = (i > 0 and partes[i-1].strip().endswith('LT'))
                        cleaned_part = self._clean_contingency_name(parte, process_options['adicionar_lt'], prev_part_ends_with_lt)
                        contingencias_data.append({
                            'Perda Dupla': cleaned_part,
                            'Futura': futura,
                            'Perdas Duplas na mesma contigencia': 'SIM' # Nome da coluna padronizado
                        })
                else:
                    cleaned_contingency = self._clean_contingency_name(contingencia, process_options['adicionar_lt'])
                    contingencias_data.append({
                        'Perda Dupla': cleaned_contingency,
                        'Futura': futura,
                        'Perdas Duplas na mesma contigencia': 'NÃO' # Nome da coluna padronizado
                    })
            else:
                cleaned_contingency = self._clean_contingency_name(contingencia, process_options['adicionar_lt'])
                contingencias_data.append({
                    'Perda Dupla': cleaned_contingency,
                    'Futura': futura,
                    'Perdas Duplas na mesma contigencia': 'NÃO' # Nome da coluna padronizado
                })
        else:
            # Retorna a contingência bruta se o processamento de regex estiver desativado
            contingencias_data.append({
                'Perda Dupla': contingencia.strip(), # Garante que a versão bruta tenha espaços extras removidos para consistência
                'Futura': futura,
                'Perdas Duplas na mesma contigencia': 'NÃO' # Valor padrão, pois não houve processamento de duplas
            })
        return contingencias_data

# ===============================================================
# CLASSE: ETLController (CONTROLLER - Camada de Lógica de Negócio)
# ===============================================================

class ETLController:
    """Orquestra as operações de ETL, utilizando o ETLRepository para acesso a dados."""

    _DEFAULT_PROCESS_OPTIONS = {
        'separar_duplas': True,
        'adicionar_lt': True,
        'enable_regex_processing': True,
        'standardize_columns': True # Nova opção para padronizar colunas
    }

    _COLUMN_NAMES = [
        'Volume',
        'Área Geoelétrica',
        'Perda Dupla',
        'Prazo',
        'Futura',
        'Perdas Duplas na mesma contigencia'
    ]

    def __init__(self):
        """Inicializa o ETLController e seu repositório de dados."""
        self._etl_repository = ETLRepository()
        self.process_options = self._DEFAULT_PROCESS_OPTIONS.copy()

    def extract_pdf_text(self, pdf_path, page_range=None):
        """
        Extrai texto de um arquivo PDF usando o ETLRepository.

        Args:
            pdf_path (str): O caminho para o arquivo PDF.
            page_range (list, optional): Uma lista de índices de páginas (base 0) a serem processadas. Se None, todas as páginas são processadas. Defaults to None.

        Returns:
            str: O texto concatenado das páginas extraídas.
        """
        return self._etl_repository.extract_text_from_pdf(pdf_path, page_range)

    def process_outro_script(self, texto):
        """
        Função placeholder para outros scripts de processamento.
        Retorna um DataFrame de exemplo.

        Args:
            texto (str): O texto a ser processado.

        Returns:
            pd.DataFrame: DataFrame de exemplo.
        """
        return pd.DataFrame({"Exemplo": ["Script 2 em desenvolvimento"]})

    def process_contingencias_duplas(self, texto):
        """
        Processa o texto extraído do PDF para identificar e tabular contingências duplas.

        Args:
            texto (str): O texto completo extraído do PDF.

        Returns:
            pd.DataFrame: Um DataFrame contendo as contingências identificadas e seus atributos.
        """
        dados = []
        volume_atual = None
        area_geoelerica_atual = None
        prazo_atual = None

        #! 1) Itera sobre cada linha do texto para extrair informações
        for linha in texto.strip().split('\n'):
            linha = linha.strip()
        
            # Ignora linhas vazias ou marcadores de página
            if not linha or linha.startswith('--- Página'):
                print(f"Linha vazia ou marcador de página: {linha}")
                continue
            
            # 2) Identifica Volume e Área Geoelétrica
            match_volume = re.match(r'(\d+\.\d+)\s+Volume\s+\d+\s*-\s*(.+)', linha)
            if match_volume:
                volume_atual = f"Volume {match_volume.group(1)}"
                area_geoelerica_atual = match_volume.group(2)
                continue
            
            # 3) Identifica Prazo (Curto Prazo ou Médio Prazo)
            match_prazo = re.match(r'\d+\.\d+\.\d+\s+(Curto\s+Prazo|Médio\s+Prazo)', linha)
            if match_prazo:
                prazo_atual = match_prazo.group(1)
                continue

            # 4) Identifica perdas duplas marcadas com '•' ou '-'
            if linha.startswith('•') or linha.startswith('-'):

                # Delega o processamento detalhado da linha de contingência ao ETLRepository
                contingencias_processadas = self._etl_repository._parse_contingency_line(
                    linha, self.process_options, prazo_atual, self.process_options['enable_regex_processing']
                )

                for c_data in contingencias_processadas:
                    # Garante que todos os dados necessários estão presentes e usa nomes de coluna padronizados
                    dados_linha = {
                        self._COLUMN_NAMES[0]: volume_atual,
                        self._COLUMN_NAMES[1]: area_geoelerica_atual,
                        self._COLUMN_NAMES[2]: c_data['Perda Dupla'],
                        self._COLUMN_NAMES[3]: prazo_atual,
                        self._COLUMN_NAMES[4]: c_data['Futura'],
                        self._COLUMN_NAMES[5]: c_data['Perdas Duplas na mesma contigencia']
                    }
                    dados.append(dados_linha)
                continue

        # Cria DataFrame a partir dos dados extraídos
        df = pd.DataFrame(dados)
        
        # Reorganiza e padroniza as colunas do DataFrame
        colunas = self._COLUMN_NAMES # Usa os nomes de coluna padronizados
        if not df.empty:
            df = df[colunas]
            
            # Verifica a opção standardize_columns antes de aplicar
            if self.process_options['standardize_columns']:
                # Padroniza a capitalização das colunas de texto usando o método privado
                df = self._standardize_dataframe_text_columns(df, [self._COLUMN_NAMES[0], self._COLUMN_NAMES[1], self._COLUMN_NAMES[2], self._COLUMN_NAMES[3]])
        
        return df

    def _standardize_dataframe_text_columns(self, df, columns_to_standardize):
        """
        Padroniza a capitalização das strings em colunas específicas de um DataFrame para o formato de título.

        Args:
            df (pd.DataFrame): O DataFrame a ser processado.
            columns_to_standardize (list): Uma lista de nomes de colunas cujos valores de string devem ser padronizados.

        Returns:
            pd.DataFrame: O DataFrame com as colunas de texto padronizadas.
        """
        for col in columns_to_standardize:
            # Verifica se a coluna existe e se é do tipo 'object' (geralmente strings)
            if col in df.columns and df[col].dtype == 'object': 
                # Aplica a função .title() a cada string na coluna
                df[col] = df[col].apply(lambda x: x.title() if isinstance(x, str) else x)
        return df


